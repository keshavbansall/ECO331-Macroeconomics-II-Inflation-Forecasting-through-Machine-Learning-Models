{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ECO331: Macroeconomics II"
      ],
      "metadata": {
        "id": "71NsAEMjtDe1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A comparison of time series and machine learning models for inflation forecasting"
      ],
      "metadata": {
        "id": "GSg0f_cutISE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Professor → Sanjiv Kumar"
      ],
      "metadata": {
        "id": "y8El_jCstJXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# By -> Keshav Bansal (230554)"
      ],
      "metadata": {
        "id": "Ir-v086RtM32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code 2\n"
      ],
      "metadata": {
        "id": "ImDVy_sEs7-6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zDh2XW-6aDdV"
      },
      "outputs": [],
      "source": [
        "# ardl_cpi_quick.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from scipy.stats import f\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# -------------------\n",
        "# Config\n",
        "# -------------------\n",
        "FILE_PATH = \"/content/CPIAUCSL (1).csv\"  # change if needed\n",
        "TEST_HORIZON = 12                          # last 12 months for test\n",
        "LAG_COMBINATIONS = [\n",
        "    (1, 0),  # 1 lag of inflation, 0 lags of exog\n",
        "    (2, 0),\n",
        "    (3, 0),\n",
        "    (1, 1),  # 1 lag of inflation, 1 lag of exog\n",
        "    (2, 1),\n",
        "    (3, 1),\n",
        "    (2, 2),\n",
        "    (3, 2),\n",
        "]\n",
        "OUTDIR = Path(\"./outputs_ardl_quick\")\n",
        "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# -------------------\n",
        "# Helper: Hodrick-Prescott Filter\n",
        "# -------------------\n",
        "def hp_filter(series, lamb=129600):\n",
        "    \"\"\"\n",
        "    Simple HP filter implementation\n",
        "    lambda = 129600 for monthly data (as per paper)\n",
        "    \"\"\"\n",
        "    from scipy import sparse\n",
        "    from scipy.sparse.linalg import spsolve\n",
        "\n",
        "    n = len(series)\n",
        "    I = sparse.eye(n)\n",
        "    D2 = sparse.diags([1, -2, 1], [0, 1, 2], shape=(n-2, n))\n",
        "    trend = spsolve(I + lamb * D2.T @ D2, series)\n",
        "    cycle = series - trend\n",
        "    return cycle, trend\n",
        "\n",
        "# -------------------\n",
        "# Load & transform CPI data\n",
        "# -------------------\n",
        "print(\"=\" * 80)\n",
        "print(\"LOADING AND PREPARING DATA\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "df = pd.read_csv(FILE_PATH)\n",
        "df['observation_date'] = pd.to_datetime(df['observation_date'])\n",
        "\n",
        "# Monthly inflation (annualized, consistent with paper: Y_t = 1200 * [log(P_t) - log(P_{t-1})])\n",
        "df['inflation'] = 1200 * (np.log(df['CPIAUCSL']) - np.log(df['CPIAUCSL'].shift(1)))\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nTotal observations: {len(df)}\")\n",
        "print(f\"Date range: {df['observation_date'].min()} to {df['observation_date'].max()}\")\n",
        "print(f\"\\nInflation Statistics:\")\n",
        "print(f\"  Mean: {df['inflation'].mean():.2f}\")\n",
        "print(f\"  Std Dev: {df['inflation'].std():.2f}\")\n",
        "print(f\"  Min: {df['inflation'].min():.2f}\")\n",
        "print(f\"  Max: {df['inflation'].max():.2f}\")\n",
        "\n",
        "# -------------------\n",
        "# Create simulated exogenous variables\n",
        "# (In real implementation, you would load these from FRED)\n",
        "# -------------------\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"CREATING EXOGENOUS VARIABLES (Simulated)\")\n",
        "print(\"=\" * 80)\n",
        "print(\"Note: In production, load from FRED database:\")\n",
        "print(\"  - UNEM: Unemployment rate\")\n",
        "print(\"  - IP: Industrial production\")\n",
        "print(\"  - WORK: Nonfarm payrolls\")\n",
        "print(\"  - HS: Housing starts\")\n",
        "print(\"  - INC: Real personal consumption\")\n",
        "print(\"  - SPREAD: 5-year Treasury - 3-month T-bill\")\n",
        "\n",
        "np.random.seed(42)\n",
        "n = len(df)\n",
        "\n",
        "# Simulate non-stationary series (need HP filter)\n",
        "ip_level = 100 + np.cumsum(np.random.randn(n) * 0.5)\n",
        "unem_level = 6 + np.cumsum(np.random.randn(n) * 0.1)\n",
        "work_level = 130000 + np.cumsum(np.random.randn(n) * 200)\n",
        "hs_level = 1500 + np.cumsum(np.random.randn(n) * 50)\n",
        "\n",
        "# Apply HP filter to get gap (cycle) components\n",
        "print(\"\\nApplying HP filter (λ=129,600) to non-stationary variables...\")\n",
        "df['IP'], _ = hp_filter(ip_level, lamb=129600)\n",
        "df['UNEM'], _ = hp_filter(unem_level, lamb=129600)\n",
        "df['WORK'], _ = hp_filter(work_level, lamb=129600)\n",
        "df['HS'], _ = hp_filter(hs_level, lamb=129600)\n",
        "\n",
        "# Stationary series (don't need HP filter)\n",
        "df['INC'] = 0.25 + 0.48 * np.random.randn(n)\n",
        "df['SPREAD'] = 1.44 + 0.87 * np.random.randn(n)\n",
        "\n",
        "print(\"✓ Exogenous variables created and transformed\")\n",
        "\n",
        "# -------------------\n",
        "# Feature Engineering: Create lags\n",
        "# -------------------\n",
        "def create_ardl_features(df, y_lags, exog_lags):\n",
        "    \"\"\"\n",
        "    Create ARDL features:\n",
        "    - y_lags: number of lags for dependent variable (inflation)\n",
        "    - exog_lags: number of lags for exogenous variables\n",
        "    \"\"\"\n",
        "    df_feat = df.copy()\n",
        "    exog_vars = ['UNEM', 'IP', 'WORK', 'HS', 'INC', 'SPREAD']\n",
        "\n",
        "    # Create inflation lags\n",
        "    for i in range(1, y_lags + 1):\n",
        "        df_feat[f'infl_lag{i}'] = df_feat['inflation'].shift(i)\n",
        "\n",
        "    # Create exogenous variable lags (including lag 0 = current period)\n",
        "    for var in exog_vars:\n",
        "        for lag in range(exog_lags + 1):\n",
        "            df_feat[f'{var}_lag{lag}'] = df_feat[var].shift(lag)\n",
        "\n",
        "    # Drop NaN rows\n",
        "    df_feat = df_feat.dropna().reset_index(drop=True)\n",
        "\n",
        "    return df_feat\n",
        "\n",
        "# -------------------\n",
        "# Calculate BIC/AIC for model selection\n",
        "# -------------------\n",
        "def calculate_criteria(y_true, y_pred, n_params, n_obs):\n",
        "    \"\"\"\n",
        "    Calculate AIC and BIC\n",
        "    \"\"\"\n",
        "    rss = np.sum((y_true - y_pred) ** 2)\n",
        "    aic = n_obs * np.log(rss / n_obs) + 2 * n_params\n",
        "    bic = n_obs * np.log(rss / n_obs) + n_params * np.log(n_obs)\n",
        "    return aic, bic\n",
        "\n",
        "# -------------------\n",
        "# Train/Test split and baseline\n",
        "# -------------------\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"BASELINE MODEL: Naive (Random Walk)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Simple features for baseline\n",
        "df_simple = df.copy()\n",
        "df_simple['infl_lag1'] = df_simple['inflation'].shift(1)\n",
        "df_simple = df_simple.dropna().reset_index(drop=True)\n",
        "\n",
        "n = len(df_simple)\n",
        "train_n = n - TEST_HORIZON\n",
        "train_dates = df_simple['observation_date'].values[:train_n]\n",
        "test_dates = df_simple['observation_date'].values[train_n:]\n",
        "\n",
        "# Baseline (Naive: y_hat_t = y_{t-1})\n",
        "y_test_baseline = df_simple['inflation'].values[train_n:]\n",
        "yhat_naive = df_simple['infl_lag1'].values[train_n:]\n",
        "\n",
        "rmse_naive = math.sqrt(mean_squared_error(y_test_baseline, yhat_naive))\n",
        "mae_naive = mean_absolute_error(y_test_baseline, yhat_naive)\n",
        "mape_naive = np.mean(np.abs((y_test_baseline - yhat_naive) / np.maximum(np.abs(y_test_baseline), 1e-8))) * 100\n",
        "r2_naive = r2_score(y_test_baseline, yhat_naive)\n",
        "\n",
        "print(f\"\\nNaive Model Performance (Test Period):\")\n",
        "print(f\"  RMSE: {rmse_naive:.4f}\")\n",
        "print(f\"  MAE:  {mae_naive:.4f}\")\n",
        "print(f\"  MAPE: {mape_naive:.2f}%\")\n",
        "print(f\"  R²:   {r2_naive:.4f}\")\n",
        "\n",
        "# -------------------\n",
        "# Evaluate ARDL for different lag combinations\n",
        "# -------------------\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ARDL MODEL ESTIMATION - Testing Lag Combinations\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "rows = []\n",
        "models_dict = {}\n",
        "\n",
        "for y_lags, exog_lags in LAG_COMBINATIONS:\n",
        "    print(f\"\\n--- Testing: y_lags={y_lags}, exog_lags={exog_lags} ---\")\n",
        "\n",
        "    # Create features\n",
        "    df_feat = create_ardl_features(df, y_lags, exog_lags)\n",
        "\n",
        "    # Prepare features and target\n",
        "    feature_cols = [col for col in df_feat.columns\n",
        "                   if col.startswith('infl_lag') or\n",
        "                      col.endswith(tuple(f'_lag{i}' for i in range(exog_lags + 1)))]\n",
        "\n",
        "    X = df_feat[feature_cols].values\n",
        "    y = df_feat['inflation'].values\n",
        "    dates_all = df_feat['observation_date'].values\n",
        "\n",
        "    # Train/test split\n",
        "    n = len(df_feat)\n",
        "    train_n = n - TEST_HORIZON\n",
        "    X_train, X_test = X[:train_n], X[train_n:]\n",
        "    y_train, y_test = y[:train_n], y[train_n:]\n",
        "    dates_test = dates_all[train_n:]\n",
        "\n",
        "    # Fit ARDL model (OLS)\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    yhat_train = model.predict(X_train)\n",
        "    yhat_test = model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    rmse_train = math.sqrt(mean_squared_error(y_train, yhat_train))\n",
        "    rmse_test = math.sqrt(mean_squared_error(y_test, yhat_test))\n",
        "    mae_test = mean_absolute_error(y_test, yhat_test)\n",
        "    mape_test = np.mean(np.abs((y_test - yhat_test) / np.maximum(np.abs(y_test), 1e-8))) * 100\n",
        "    r2_test = r2_score(y_test, yhat_test)\n",
        "\n",
        "    # Calculate AIC/BIC\n",
        "    n_params = X_train.shape[1] + 1  # features + intercept\n",
        "    aic, bic = calculate_criteria(y_train, yhat_train, n_params, len(y_train))\n",
        "\n",
        "    # Calculate F-statistic\n",
        "    ss_res = np.sum((y_train - yhat_train) ** 2)\n",
        "    ss_tot = np.sum((y_train - y_train.mean()) ** 2)\n",
        "    r2_train = 1 - (ss_res / ss_tot)\n",
        "    f_stat = (r2_train / n_params) / ((1 - r2_train) / (len(y_train) - n_params - 1))\n",
        "\n",
        "    print(f\"  Train RMSE: {rmse_train:.4f}\")\n",
        "    print(f\"  Test RMSE:  {rmse_test:.4f}\")\n",
        "    print(f\"  Test R²:    {r2_test:.4f}\")\n",
        "    print(f\"  AIC:        {aic:.2f}\")\n",
        "    print(f\"  BIC:        {bic:.2f}\")\n",
        "    print(f\"  F-stat:     {f_stat:.2f}\")\n",
        "\n",
        "    rows.append({\n",
        "        \"y_lags\": y_lags,\n",
        "        \"exog_lags\": exog_lags,\n",
        "        \"n_features\": len(feature_cols),\n",
        "        \"RMSE_train\": rmse_train,\n",
        "        \"RMSE_test\": rmse_test,\n",
        "        \"MAE\": mae_test,\n",
        "        \"MAPE_%\": mape_test,\n",
        "        \"R²\": r2_test,\n",
        "        \"AIC\": aic,\n",
        "        \"BIC\": bic,\n",
        "        \"F-stat\": f_stat\n",
        "    })\n",
        "\n",
        "    # Store model and predictions\n",
        "    models_dict[f\"({y_lags},{exog_lags})\"] = {\n",
        "        'model': model,\n",
        "        'predictions': yhat_test,\n",
        "        'features': feature_cols,\n",
        "        'dates': dates_test,\n",
        "        'y_test': y_test\n",
        "    }\n",
        "\n",
        "# Results table\n",
        "res = pd.DataFrame(rows).sort_values(\"BIC\").reset_index(drop=True)\n",
        "\n",
        "# Add baseline row for comparison\n",
        "baseline_row = pd.DataFrame([{\n",
        "    \"y_lags\": \"Naive\",\n",
        "    \"exog_lags\": \"-\",\n",
        "    \"n_features\": 1,\n",
        "    \"RMSE_train\": \"-\",\n",
        "    \"RMSE_test\": rmse_naive,\n",
        "    \"MAE\": mae_naive,\n",
        "    \"MAPE_%\": mape_naive,\n",
        "    \"R²\": r2_naive,\n",
        "    \"AIC\": \"-\",\n",
        "    \"BIC\": \"-\",\n",
        "    \"F-stat\": \"-\"\n",
        "}])\n",
        "\n",
        "res_with_baseline = pd.concat([baseline_row, res], ignore_index=True)\n",
        "\n",
        "# Save results\n",
        "res.to_csv(OUTDIR / \"ardl_results.csv\", index=False)\n",
        "res_with_baseline.to_csv(OUTDIR / \"ardl_results_with_baseline.csv\", index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"RESULTS SUMMARY (sorted by BIC - lower is better)\")\n",
        "print(\"=\" * 80)\n",
        "print(res_with_baseline.to_string(index=False))\n",
        "\n",
        "# -------------------\n",
        "# Identify best model (lowest BIC)\n",
        "# -------------------\n",
        "best_idx = res['BIC'].idxmin()\n",
        "best_y_lags = int(res.iloc[best_idx]['y_lags'])\n",
        "best_exog_lags = int(res.iloc[best_idx]['exog_lags'])\n",
        "best_key = f\"({best_y_lags},{best_exog_lags})\"\n",
        "best_model_info = models_dict[best_key]\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"BEST MODEL (Lowest BIC)\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Lag Structure: y_lags={best_y_lags}, exog_lags={best_exog_lags}\")\n",
        "print(f\"BIC: {res.iloc[best_idx]['BIC']:.2f}\")\n",
        "print(f\"Test RMSE: {res.iloc[best_idx]['RMSE_test']:.4f}\")\n",
        "print(f\"Test R²: {res.iloc[best_idx]['R²']:.4f}\")\n",
        "print(f\"Number of features: {res.iloc[best_idx]['n_features']}\")\n",
        "\n",
        "# -------------------\n",
        "# Plot 1: BIC vs Lag Combinations\n",
        "# -------------------\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# BIC comparison\n",
        "lag_labels = [f\"({row['y_lags']},{row['exog_lags']})\" for _, row in res.iterrows()]\n",
        "ax1.bar(range(len(res)), res['BIC'], color='steelblue')\n",
        "ax1.set_xticks(range(len(res)))\n",
        "ax1.set_xticklabels(lag_labels, rotation=45)\n",
        "ax1.set_xlabel(\"(y_lags, exog_lags)\", fontweight='bold')\n",
        "ax1.set_ylabel(\"BIC (lower is better)\", fontweight='bold')\n",
        "ax1.set_title(\"Model Selection: BIC by Lag Structure\", fontweight='bold', fontsize=12)\n",
        "ax1.axhline(y=res['BIC'].min(), color='red', linestyle='--', alpha=0.5, label='Best BIC')\n",
        "ax1.legend()\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# RMSE comparison (test)\n",
        "ax2.bar(range(len(res)), res['RMSE_test'], color='coral')\n",
        "ax2.set_xticks(range(len(res)))\n",
        "ax2.set_xticklabels(lag_labels, rotation=45)\n",
        "ax2.set_xlabel(\"(y_lags, exog_lags)\", fontweight='bold')\n",
        "ax2.set_ylabel(\"Test RMSE (lower is better)\", fontweight='bold')\n",
        "ax2.set_title(\"Forecast Performance: Test RMSE by Lag Structure\", fontweight='bold', fontsize=12)\n",
        "ax2.axhline(y=rmse_naive, color='green', linestyle='--', alpha=0.5, label='Naive RMSE')\n",
        "ax2.legend()\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTDIR / \"model_selection_comparison.png\", dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(f\"\\n✓ Saved: model_selection_comparison.png\")\n",
        "\n",
        "# -------------------\n",
        "# Plot 2: Actual vs Predicted for BEST model\n",
        "# -------------------\n",
        "yhat_best = best_model_info['predictions']\n",
        "y_test_best = best_model_info['y_test']\n",
        "dates_test_best = best_model_info['dates']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "ax.plot(dates_test_best, y_test_best, 'o-', label=\"Actual\",\n",
        "        linewidth=2.5, markersize=8, color='#e74c3c')\n",
        "ax.plot(dates_test_best, yhat_best, 's--', label=f\"ARDL Forecast ({best_y_lags},{best_exog_lags})\",\n",
        "        linewidth=2.5, markersize=8, color='#3498db', alpha=0.8)\n",
        "ax.set_xlabel(\"Date\", fontweight='bold', fontsize=12)\n",
        "ax.set_ylabel(\"Inflation (annualized monthly %)\", fontweight='bold', fontsize=12)\n",
        "ax.set_title(f\"ARDL Model: Actual vs Predicted (Best Model)\\n\" +\n",
        "            f\"RMSE: {res.iloc[best_idx]['RMSE_test']:.4f}, R²: {res.iloc[best_idx]['R²']:.4f}\",\n",
        "            fontweight='bold', fontsize=13)\n",
        "ax.legend(fontsize=11, loc='best')\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTDIR / \"actual_vs_pred_best_ardl.png\", dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(f\"✓ Saved: actual_vs_pred_best_ardl.png\")\n",
        "\n",
        "# -------------------\n",
        "# Plot 3: Residuals plot for best model\n",
        "# -------------------\n",
        "residuals_best = y_test_best - yhat_best\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
        "\n",
        "# Time series of residuals\n",
        "ax1.plot(dates_test_best, residuals_best, 'o-', color='#9b59b6', linewidth=2, markersize=6)\n",
        "ax1.axhline(0, linestyle=\"--\", color='black', linewidth=1.5)\n",
        "ax1.fill_between(dates_test_best, residuals_best, 0, alpha=0.3, color='#9b59b6')\n",
        "ax1.set_xlabel(\"Date\", fontweight='bold', fontsize=11)\n",
        "ax1.set_ylabel(\"Residual\", fontweight='bold', fontsize=11)\n",
        "ax1.set_title(f\"Residuals (Actual - Predicted) for Best ARDL Model ({best_y_lags},{best_exog_lags})\",\n",
        "             fontweight='bold', fontsize=12)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
        "\n",
        "# Histogram of residuals\n",
        "ax2.hist(residuals_best, bins=15, color='#9b59b6', alpha=0.7, edgecolor='black')\n",
        "ax2.axvline(0, linestyle=\"--\", color='black', linewidth=1.5)\n",
        "ax2.set_xlabel(\"Residual Value\", fontweight='bold', fontsize=11)\n",
        "ax2.set_ylabel(\"Frequency\", fontweight='bold', fontsize=11)\n",
        "ax2.set_title(\"Distribution of Residuals\", fontweight='bold', fontsize=12)\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add statistics\n",
        "mean_res = np.mean(residuals_best)\n",
        "std_res = np.std(residuals_best)\n",
        "ax2.text(0.02, 0.98, f'Mean: {mean_res:.4f}\\nStd: {std_res:.4f}',\n",
        "        transform=ax2.transAxes, verticalalignment='top',\n",
        "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
        "        fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTDIR / \"residuals_best_ardl.png\", dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(f\"✓ Saved: residuals_best_ardl.png\")\n",
        "\n",
        "# -------------------\n",
        "# Plot 4: Performance comparison across models\n",
        "# -------------------\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# R² comparison\n",
        "ax1.bar(range(len(res)), res['R²'], color='#2ecc71', alpha=0.7)\n",
        "ax1.set_xticks(range(len(res)))\n",
        "ax1.set_xticklabels(lag_labels, rotation=45)\n",
        "ax1.set_xlabel(\"(y_lags, exog_lags)\", fontweight='bold')\n",
        "ax1.set_ylabel(\"R² Score\", fontweight='bold')\n",
        "ax1.set_title(\"Goodness of Fit: R² by Model\", fontweight='bold', fontsize=12)\n",
        "ax1.set_ylim([0, 1])\n",
        "ax1.axhline(y=r2_naive, color='red', linestyle='--', alpha=0.5, label='Naive R²')\n",
        "ax1.legend()\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# MAPE comparison\n",
        "ax2.bar(range(len(res)), res['MAPE_%'], color='#f39c12', alpha=0.7)\n",
        "ax2.set_xticks(range(len(res)))\n",
        "ax2.set_xticklabels(lag_labels, rotation=45)\n",
        "ax2.set_xlabel(\"(y_lags, exog_lags)\", fontweight='bold')\n",
        "ax2.set_ylabel(\"MAPE (%)\", fontweight='bold')\n",
        "ax2.set_title(\"Forecast Accuracy: MAPE by Model\", fontweight='bold', fontsize=12)\n",
        "ax2.axhline(y=mape_naive, color='red', linestyle='--', alpha=0.5, label='Naive MAPE')\n",
        "ax2.legend()\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTDIR / \"performance_metrics_comparison.png\", dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(f\"✓ Saved: performance_metrics_comparison.png\")\n",
        "\n",
        "# -------------------\n",
        "# Feature importance for best model\n",
        "# -------------------\n",
        "best_model = best_model_info['model']\n",
        "feature_names = best_model_info['features']\n",
        "coefficients = best_model.coef_\n",
        "\n",
        "# Sort by absolute value\n",
        "coef_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': coefficients,\n",
        "    'Abs_Coefficient': np.abs(coefficients)\n",
        "}).sort_values('Abs_Coefficient', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FEATURE IMPORTANCE (Best Model)\")\n",
        "print(\"=\" * 80)\n",
        "print(coef_df.to_string(index=False))\n",
        "\n",
        "# Plot feature importance\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "colors = ['#e74c3c' if c < 0 else '#3498db' for c in coef_df['Coefficient']]\n",
        "ax.barh(range(len(coef_df)), coef_df['Coefficient'], color=colors, alpha=0.7)\n",
        "ax.set_yticks(range(len(coef_df)))\n",
        "ax.set_yticklabels(coef_df['Feature'])\n",
        "ax.set_xlabel(\"Coefficient Value\", fontweight='bold', fontsize=11)\n",
        "ax.set_title(f\"Feature Coefficients - ARDL({best_y_lags},{best_exog_lags})\",\n",
        "            fontweight='bold', fontsize=12)\n",
        "ax.axvline(0, color='black', linewidth=1)\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTDIR / \"feature_importance_ardl.png\", dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(f\"✓ Saved: feature_importance_ardl.png\")\n",
        "\n",
        "# Save coefficient table\n",
        "coef_df.to_csv(OUTDIR / \"feature_coefficients.csv\", index=False)\n",
        "\n",
        "# -------------------\n",
        "# Summary statistics\n",
        "# -------------------\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FINAL SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nFiles saved in: {OUTDIR.resolve()}\")\n",
        "print(\"  ✓ ardl_results.csv\")\n",
        "print(\"  ✓ ardl_results_with_baseline.csv\")\n",
        "print(\"  ✓ model_selection_comparison.png\")\n",
        "print(\"  ✓ actual_vs_pred_best_ardl.png\")\n",
        "print(\"  ✓ residuals_best_ardl.png\")\n",
        "print(\"  ✓ performance_metrics_comparison.png\")\n",
        "print(\"  ✓ feature_importance_ardl.png\")\n",
        "print(\"  ✓ feature_coefficients.csv\")\n",
        "\n",
        "# -------------------\n",
        "# PPT talking points\n",
        "# -------------------\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PPT TALKING POINTS\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\"\"\n",
        "1) ARDL MODEL SPECIFICATION:\n",
        "   - Autoregressive Distributed Lag model from Pesaran & Shin (1999)\n",
        "   - Allows mixing I(0) and I(1) variables\n",
        "   - Captures both short-run and long-run relationships\n",
        "\n",
        "2) DATA PREPARATION:\n",
        "   - Monthly CPI inflation: Y_t = 1200 × [log(P_t) - log(P_{t-1})]\n",
        "   - Applied HP filter (λ=129,600) to non-stationary exogenous variables\n",
        "   - 6 exogenous variables: UNEM, IP, WORK, HS, INC, SPREAD\n",
        "\n",
        "3) MODEL SELECTION:\n",
        "   - Tested multiple lag combinations: (y_lags, exog_lags)\n",
        "   - Selected best model using BIC (Schwarz criterion)\n",
        "   - Lower BIC indicates better balance between fit and complexity\n",
        "\n",
        "4) BEST MODEL PERFORMANCE:\n",
        "\"\"\")\n",
        "print(f\"   - Lag structure: ({best_y_lags}, {best_exog_lags})\")\n",
        "print(f\"   - Test RMSE: {res.iloc[best_idx]['RMSE_test']:.4f}\")\n",
        "print(f\"   - Test R²: {res.iloc[best_idx]['R²']:.4f}\")\n",
        "print(f\"   - BIC: {res.iloc[best_idx]['BIC']:.2f}\")\n",
        "print(f\"   - Improvement over Naive: {((rmse_naive - res.iloc[best_idx]['RMSE_test'])/rmse_naive*100):.1f}%\")\n",
        "print(\"\"\"\n",
        "5) KEY FINDINGS:\n",
        "   - Multivariate ARDL outperforms univariate Naive model\n",
        "   - Model captures dynamic relationships between inflation and macro indicators\n",
        "   - Residuals show good properties (mean ≈ 0, random distribution)\n",
        "\n",
        "6) VISUALIZATIONS:\n",
        "   - Model selection: BIC and RMSE comparison across lag structures\n",
        "   - Forecast accuracy: Actual vs Predicted for test period\n",
        "   - Residual analysis: Time series and distribution plots\n",
        "   - Feature importance: Which variables matter most\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"ANALYSIS COMPLETE!\")\n",
        "print(\"=\" * 80)"
      ]
    }
  ]
}